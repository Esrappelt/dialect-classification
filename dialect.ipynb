{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:21:01.496045Z",
     "start_time": "2024-09-09T14:20:59.308972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForAudioClassification, EvalPrediction"
   ],
   "id": "1d7d31a994d424e4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:21:01.498938Z",
     "start_time": "2024-09-09T14:21:01.496859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "6b98deb7e9f929d8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:21:01.501921Z",
     "start_time": "2024-09-09T14:21:01.499774Z"
    }
   },
   "cell_type": "code",
   "source": "model_name_or_path = \"/home/xiaoyujie/hf-models/TencentGameMate/chinese-hubert-large\"",
   "id": "91a61a2306928e4f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:21:01.733178Z",
     "start_time": "2024-09-09T14:21:01.503407Z"
    }
   },
   "cell_type": "code",
   "source": "from datasets import load_dataset, Audio",
   "id": "5bb54221c003b253",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:21:01.736025Z",
     "start_time": "2024-09-09T14:21:01.734022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_files = {\n",
    "    \"train\": \"train.csv\",\n",
    "    \"dev\": \"dev.csv\",\n",
    "    \"test\": \"test.csv\"\n",
    "}"
   ],
   "id": "83317be641de578c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:21:02.803762Z",
     "start_time": "2024-09-09T14:21:01.736885Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = load_dataset('csv', data_files=dataset_files, name=\"kespeech\")",
   "id": "ae9d883dbca0b725",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dataset",
   "id": "8981a970461904d9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio_path', 'label'],\n",
       "        num_rows: 267142\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['audio_path', 'label'],\n",
       "        num_rows: 1080\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['audio_path', 'label'],\n",
       "        num_rows: 9559\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:21:02.841331Z",
     "start_time": "2024-09-09T14:21:02.813370Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = dataset.cast_column(\"audio_path\", Audio(sampling_rate=16_000))",
   "id": "56037fd0cb90ce11",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:21:02.901892Z",
     "start_time": "2024-09-09T14:21:02.842532Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = dataset.class_encode_column(column='label')",
   "id": "fb61de59ced3324c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:21:02.905177Z",
     "start_time": "2024-09-09T14:21:02.903157Z"
    }
   },
   "cell_type": "code",
   "source": "labels = dataset[\"train\"].features[\"label\"].names",
   "id": "9b8364439f3f2234",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:21:02.908459Z",
     "start_time": "2024-09-09T14:21:02.905990Z"
    }
   },
   "cell_type": "code",
   "source": "labels",
   "id": "129d078881903377",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Beijing',\n",
       " 'Ji-Lu',\n",
       " 'Jiang-Huai',\n",
       " 'Jiao-Liao',\n",
       " 'Lan-Yin',\n",
       " 'Mandarin',\n",
       " 'Northeastern',\n",
       " 'Southwestern',\n",
       " 'Zhongyuan']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:21:02.911080Z",
     "start_time": "2024-09-09T14:21:02.909166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label"
   ],
   "id": "bc3eba690517636d",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:21:02.916892Z",
     "start_time": "2024-09-09T14:21:02.911707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name_or_path)"
   ],
   "id": "f9e84b06e6fe1079",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:21:02.919465Z",
     "start_time": "2024-09-09T14:21:02.917555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_function(examples):\n",
    "    audio_arrays = [x[\"array\"] for x in examples[\"audio_path\"]]\n",
    "    inputs = feature_extractor(audio_arrays, sampling_rate=feature_extractor.sampling_rate)\n",
    "    return inputs"
   ],
   "id": "6609d16ce89a4ef9",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:21:04.376506Z",
     "start_time": "2024-09-09T14:21:02.920164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoded_dataset = dataset.map(preprocess_function, remove_columns=\"audio_path\", batched=True, num_proc=4,\n",
    "                              batch_size=100)"
   ],
   "id": "5329952facddf9e1",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:21:04.400210Z",
     "start_time": "2024-09-09T14:21:04.377568Z"
    }
   },
   "cell_type": "code",
   "source": "len(encoded_dataset[\"train\"][0]['input_values'])",
   "id": "929357f7d07c7fe7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50864"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:21:04.404259Z",
     "start_time": "2024-09-09T14:21:04.401201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "np.arange(100).tolist()"
   ],
   "id": "5c188b7e6e1cd4c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:21:04.689379Z",
     "start_time": "2024-09-09T14:21:04.405834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import f1_score, classification_report, precision_score, accuracy_score\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(eval_pred.label_ids, eval_pred.predictions.argmax(axis=-1)),\n",
    "        \"precision\": precision_score(eval_pred.label_ids, eval_pred.predictions.argmax(axis=-1), average=\"macro\"),\n",
    "        \"f1\": f1_score(eval_pred.label_ids, eval_pred.predictions.argmax(axis=-1), average=\"macro\"),\n",
    "    }"
   ],
   "id": "830b331665f27ca3",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:24:03.494713Z",
     "start_time": "2024-09-09T14:24:03.491162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "from transformers import HubertForSequenceClassification\n",
    "\n",
    "\n",
    "class TransformerProjector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransformerProjector, self).__init__()\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=1024, nhead=16),\n",
    "            num_layers=1,\n",
    "        )\n",
    "        self.trans = nn.Linear(1024, 256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.trans(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class HubertTransformerForAudioClassification(HubertForSequenceClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.projector = TransformerProjector()\n",
    "        self.post_init()"
   ],
   "id": "422bb4979b94ae47",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:24:04.453433Z",
     "start_time": "2024-09-09T14:24:04.312034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "num_labels = len(id2label)\n",
    "model = HubertTransformerForAudioClassification.from_pretrained(\n",
    "    model_name_or_path, num_labels=num_labels, label2id=label2id, id2label=id2label\n",
    ")"
   ],
   "id": "8ace7cee8a77867",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of HubertTransformerForAudioClassification were not initialized from the model checkpoint at /home/xiaoyujie/hf-models/TencentGameMate/chinese-hubert-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'projector.trans.bias', 'projector.trans.weight', 'projector.transformer_encoder.layers.0.linear1.bias', 'projector.transformer_encoder.layers.0.linear1.weight', 'projector.transformer_encoder.layers.0.linear2.bias', 'projector.transformer_encoder.layers.0.linear2.weight', 'projector.transformer_encoder.layers.0.norm1.bias', 'projector.transformer_encoder.layers.0.norm1.weight', 'projector.transformer_encoder.layers.0.norm2.bias', 'projector.transformer_encoder.layers.0.norm2.weight', 'projector.transformer_encoder.layers.0.self_attn.in_proj_bias', 'projector.transformer_encoder.layers.0.self_attn.in_proj_weight', 'projector.transformer_encoder.layers.0.self_attn.out_proj.bias', 'projector.transformer_encoder.layers.0.self_attn.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:24:05.090245Z",
     "start_time": "2024-09-09T14:24:05.088051Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "3a8f034a6348e387",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:24:07.969793Z",
     "start_time": "2024-09-09T14:24:07.966694Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.is_available()",
   "id": "7628b6cb18386854",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:24:08.234724Z",
     "start_time": "2024-09-09T14:24:08.230553Z"
    }
   },
   "cell_type": "code",
   "source": "model.freeze_base_model()",
   "id": "93bd2e9a78cb54a1",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:24:08.559493Z",
     "start_time": "2024-09-09T14:24:08.551802Z"
    }
   },
   "cell_type": "code",
   "source": "model",
   "id": "3ae56d0d34f24e74",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HubertTransformerForAudioClassification(\n",
       "  (hubert): HubertModel(\n",
       "    (feature_extractor): HubertFeatureEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): HubertLayerNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (1-4): 4 x HubertLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (5-6): 2 x HubertLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): HubertFeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): HubertEncoderStableLayerNorm(\n",
       "      (pos_conv_embed): HubertPositionalConvEmbedding(\n",
       "        (conv): ParametrizedConv1d(\n",
       "          1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (padding): HubertSamePadLayer()\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x HubertEncoderLayerStableLayerNorm(\n",
       "          (attention): HubertSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): HubertFeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (projector): TransformerProjector(\n",
       "    (transformer_encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (trans): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=256, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:24:09.243010Z",
     "start_time": "2024-09-09T14:24:09.240598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_model_training_params(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f'{total_params:,} total parameters.')\n",
    "    total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f'{total_trainable_params:,} training parameters.')"
   ],
   "id": "ec9fd931990b7a65",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:24:09.870665Z",
     "start_time": "2024-09-09T14:24:09.861858Z"
    }
   },
   "cell_type": "code",
   "source": "get_model_training_params(model)",
   "id": "1205027145f4e13d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324,099,721 total parameters.\n",
      "8,664,585 training parameters.\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:24:10.207842Z",
     "start_time": "2024-09-09T14:24:10.204119Z"
    }
   },
   "cell_type": "code",
   "source": "encoded_dataset[\"dev\"]",
   "id": "2664e052759ba110",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_values', 'attention_mask'],\n",
       "    num_rows: 1080\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T15:22:48.392638Z",
     "start_time": "2024-09-09T15:22:48.373086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"models\",\n",
    "    logging_dir=\"logs\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=10000,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=10000,\n",
    "    learning_rate=1e-3,\n",
    "    fp16=False,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    logging_steps=10000,\n",
    "    num_train_epochs=2,\n",
    ")"
   ],
   "id": "37bc704708fc3497",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T15:22:49.244613Z",
     "start_time": "2024-09-09T15:22:49.236879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"dev\"],\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "id": "d118e9b6e00dd424",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-09-09T15:22:52.228763Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "304fab9111fd16c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='267142' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [     5/267142 00:00 < 13:32:58, 5.48 it/s, Epoch 0.00/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c9a5e385c40992ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9501abd51be8648d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ad789d5d32b9a1f6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
